{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1aca195-c192-44a5-9a68-9438d6e67209",
   "metadata": {},
   "source": [
    "# Set up the Jupyter notebook environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb5599-afc7-4ea4-9ec1-44219f2b072a",
   "metadata": {},
   "source": [
    "Install the Google Cloud Vertex AI, Cloud Storage and BigQuery SDKs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c025ccd6-64bd-4e39-aab3-b97f32a06ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in ./.local/lib/python3.10/site-packages (1.94.0)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.19.0)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery[pandas] in ./.local/lib/python3.10/site-packages (3.33.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.38.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (24.2)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.0.7)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in ./.local/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.16.1)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (4.13.0)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (2.2.3)\n",
      "Requirement already satisfied: pandas-gbq>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (0.28.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.47.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (1.71.0)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (19.0.1)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery[pandas]) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from db-dtypes<2.0.0,>=1.0.4->google-cloud-bigquery[pandas]) (2.1.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.69.2)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (4.9.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in ./.local/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.28.1)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (15.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->google-cloud-bigquery[pandas]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->google-cloud-bigquery[pandas]) (2025.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pandas-gbq>=0.26.1->google-cloud-bigquery[pandas]) (75.8.2)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq>=0.26.1->google-cloud-bigquery[pandas]) (1.9.1)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq>=0.26.1->google-cloud-bigquery[pandas]) (1.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery[pandas]) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.1.31)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq>=0.26.1->google-cloud-bigquery[pandas]) (2.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.local/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.16.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq>=0.26.1->google-cloud-bigquery[pandas]) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade google-cloud-aiplatform \\\n",
    "                        google-cloud-storage \\\n",
    "                        'google-cloud-bigquery[pandas]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc3634-f415-462e-a838-80310d64ea04",
   "metadata": {},
   "source": [
    "Restart kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c82a981-1a78-40b3-aec4-2d1aff33bb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5704f-e4eb-4f98-b2c0-46a30a5b01cb",
   "metadata": {},
   "source": [
    "Setup the environment values for your project\n",
    "\n",
    "Setting up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc074a18-92a1-4a66-a0fe-52fd896429b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-west1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda09f8-2dd4-48cb-a6a3-a2dd6ca8720b",
   "metadata": {},
   "source": [
    "Import and initialize the Vertex AI Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853027dc-8efa-4c3d-b833-77954e1a8bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "vertexai.init(project = PROJECT_ID,\n",
    "              location = REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b00c6a-8d7f-49ab-8a1b-9bbf82a8fe91",
   "metadata": {},
   "source": [
    "# Prepare the data in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32d923-4c0e-4ed6-babb-e01bea2d620e",
   "metadata": {},
   "source": [
    "The dataset used for this lab is the [StackOverflow dataset](https://console.cloud.google.com/marketplace/product/stack-exchange/stack-overflow?inv=1&invt=Abylhg&project=qwiklabs-gcp-02-9c2eecad5f04). This public dataset is hosted in Google BigQuery and is included in BigQuery's 1TB/mo of free tier processing. This means that each user receives 1TB of free BigQuery processing every month, which can be used to run queries on this public dataset.\n",
    "\n",
    "Stack Overflow is the largest online community for programmers to learn, share their knowledge, and advance their careers. Updated on a quarterly basis, this BigQuery dataset includes an archive of Stack Overflow content, including posts, votes, tags, and badges. This dataset is updated to mirror the Stack Overflow content on the Internet Archive, and is also available through the Stack Exchange Data Explorer.\n",
    "\n",
    "The BigQuery table is too large to fit into memory, so you need to write a generator called `query_bigquery_chunks` to yield chunks of the dataframe for processing. Additionally, an extra column `title_with_body` is added, which is a concatenation of the question title and body that will be used for creating embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7336c-2c8b-42a3-b1f1-6ebeb98e88cd",
   "metadata": {},
   "source": [
    "Import the libraries and initialize the BigQuery client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e6c4b8-ebb9-42ab-b007-5a770788e25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any, Generator\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774df719-7b29-4bd8-ad7e-612243a551c8",
   "metadata": {},
   "source": [
    "Define the BigQuery query for the remote dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed73d5e5-4e5f-41db-8d81-8e1e119d481d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "QUERY_TEMPLATE = \"\"\"\n",
    "        SELECT distinct q.id, q.title, q.body\n",
    "        FROM (SELECT * FROM `bigquery-public-data.stackoverflow.posts_questions` where Score>0 ORDER BY View_Count desc) AS q\n",
    "        LIMIT {limit} OFFSET {offset};\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaffdc95-c7d5-410a-bb42-b74dd011a8e3",
   "metadata": {},
   "source": [
    "Create a function to access the BigQuery data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad371bb-0903-4077-b139-642beba090b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_bigquery_chunks(\n",
    "    max_rows: int, rows_per_chunk: int, start_chunk: int = 0\n",
    ") -> Generator[pd.DataFrame, Any, None]:\n",
    "    for offset in range(start_chunk, max_rows, rows_per_chunk):\n",
    "        query = QUERY_TEMPLATE.format(limit=rows_per_chunk, offset=offset)\n",
    "        query_job = client.query(query)\n",
    "        rows = query_job.result()\n",
    "        df = rows.to_dataframe()\n",
    "        df[\"title_with_body\"] = df.title + \"\\n\" + df.body\n",
    "        yield df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb8c68-69f1-4363-9eb5-5545e1a5b601",
   "metadata": {},
   "source": [
    "Get a dataframe of 1000 rows for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d0e79b8-b9b2-450d-84db-5490cd0430c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>title_with_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9257858</td>\n",
       "      <td>Get mutual subscriptions between two users</td>\n",
       "      <td>&lt;p&gt;I have a table as follows&lt;/p&gt;\\n\\n&lt;pre&gt;&lt;code...</td>\n",
       "      <td>Get mutual subscriptions between two users\\n&lt;p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9243623</td>\n",
       "      <td>UITableView not selecting properly</td>\n",
       "      <td>&lt;p&gt;I am working on an iPhone app, where I have...</td>\n",
       "      <td>UITableView not selecting properly\\n&lt;p&gt;I am wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9459273</td>\n",
       "      <td>.Ajax method works on local machine, but not o...</td>\n",
       "      <td>&lt;p&gt;I have an .Ajax method that calls a method ...</td>\n",
       "      <td>.Ajax method works on local machine, but not o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4569123</td>\n",
       "      <td>Content is not allowed in Prolog SAXParserExce...</td>\n",
       "      <td>&lt;p&gt;I am trying to call a web service but facin...</td>\n",
       "      <td>Content is not allowed in Prolog SAXParserExce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4308934</td>\n",
       "      <td>How to delete last character from a string usi...</td>\n",
       "      <td>&lt;p&gt;How to delete last character from a string ...</td>\n",
       "      <td>How to delete last character from a string usi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  9257858         Get mutual subscriptions between two users   \n",
       "1  9243623                 UITableView not selecting properly   \n",
       "2  9459273  .Ajax method works on local machine, but not o...   \n",
       "3  4569123  Content is not allowed in Prolog SAXParserExce...   \n",
       "4  4308934  How to delete last character from a string usi...   \n",
       "\n",
       "                                                body  \\\n",
       "0  <p>I have a table as follows</p>\\n\\n<pre><code...   \n",
       "1  <p>I am working on an iPhone app, where I have...   \n",
       "2  <p>I have an .Ajax method that calls a method ...   \n",
       "3  <p>I am trying to call a web service but facin...   \n",
       "4  <p>How to delete last character from a string ...   \n",
       "\n",
       "                                     title_with_body  \n",
       "0  Get mutual subscriptions between two users\\n<p...  \n",
       "1  UITableView not selecting properly\\n<p>I am wo...  \n",
       "2  .Ajax method works on local machine, but not o...  \n",
       "3  Content is not allowed in Prolog SAXParserExce...  \n",
       "4  How to delete last character from a string usi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = next(query_bigquery_chunks(max_rows=1000, rows_per_chunk=1000))\n",
    "\n",
    "# Examine the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b76ee1-ec85-4725-a6dc-23c000825e71",
   "metadata": {},
   "source": [
    "# Create text embeddings from BigQuery data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514239fb-0a11-4f21-b544-424c594acedc",
   "metadata": {},
   "source": [
    "Load the `Vertex AI Embeddings` for Text model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56313e1e-eca3-47b5-928c-81172af8c7f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from vertexai.preview.language_models import TextEmbeddingModel\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad02e9-62ff-4e57-b95f-72ba267413d9",
   "metadata": {},
   "source": [
    "Define an embedding method that uses the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6eef57a-19c2-4c3d-96a8-6218e6e868d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_texts_to_embeddings(sentences: List[str]) -> List[Optional[List[float]]]:\n",
    "    try:\n",
    "        embeddings = model.get_embeddings(sentences)\n",
    "        return [embedding.values for embedding in embeddings]\n",
    "    except Exception:\n",
    "        return [None for _ in range(len(sentences))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91186498-c414-4a1e-bf8e-f0ded8127902",
   "metadata": {},
   "source": [
    "According to the documentation, each request can handle up to 5 text instances. So we will need to split the BigQuery question results in batches of 5 before sending to the embedding API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97e9f8-6194-41c8-8fc4-c702eeca92ab",
   "metadata": {},
   "source": [
    "Create a `generate_batches` to split results in batches of 5 to be sent to the embeddings API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec95c871-6025-48cd-a5fa-d8d35f116796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Generator, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Generator function to yield batches of sentences\n",
    "def generate_batches(\n",
    "    sentences: List[str], batch_size: int\n",
    ") -> Generator[List[str], None, None]:\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        yield sentences[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae7792-83e7-444b-bf6b-e3357c2c0248",
   "metadata": {},
   "source": [
    "Encapsulate the process of generating batches and calling the embeddings API in a method called `encode_text_to_embedding_batched`. \n",
    "This method also handles `rate-limiting` using `time.sleep`. \n",
    "For production use cases, you would want a more sophisticated rate-limiting mechanism that takes retries into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "767c3b65-f99e-4252-8b03-a7de7b0f71f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_text_to_embedding_batched(\n",
    "    sentences: List[str], api_calls_per_second: int = 10, batch_size: int = 5\n",
    ") -> Tuple[List[bool], np.ndarray]:\n",
    "\n",
    "    embeddings_list: List[List[float]] = []\n",
    "\n",
    "    # Prepare the batches using a generator\n",
    "    batches = generate_batches(sentences, batch_size)\n",
    "\n",
    "    seconds_per_job = 1 / api_calls_per_second\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for batch in tqdm(\n",
    "            batches, total=math.ceil(len(sentences) / batch_size), position=0\n",
    "        ):\n",
    "            futures.append(\n",
    "                executor.submit(functools.partial(encode_texts_to_embeddings), batch)\n",
    "            )\n",
    "            time.sleep(seconds_per_job)\n",
    "\n",
    "        for future in futures:\n",
    "            embeddings_list.extend(future.result())\n",
    "\n",
    "    is_successful = [\n",
    "        embedding is not None for sentence, embedding in zip(sentences, embeddings_list)\n",
    "    ]\n",
    "    embeddings_list_successful = np.squeeze(\n",
    "        np.stack([embedding for embedding in embeddings_list if embedding is not None])\n",
    "    )\n",
    "    return is_successful, embeddings_list_successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd59de-ea37-4d5b-be27-2bbb5e8a3e57",
   "metadata": {},
   "source": [
    "Test the encoding function by encoding a subset of data and see if the embeddings and distance metrics make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f3f70b-647b-4396-8389-825aa504dd27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b2d210a2c34ddebddbc8e8dcd7b3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode a subset of questions for validation\n",
    "questions = df.title.tolist()[:500]\n",
    "is_successful, question_embeddings = encode_text_to_embedding_batched(\n",
    "    sentences=df.title.tolist()[:500]\n",
    ")\n",
    "\n",
    "# Filter for successfully embedded sentences\n",
    "questions = np.array(questions)[is_successful]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5d97c-fdd1-42de-bb65-5eeac501fdcc",
   "metadata": {},
   "source": [
    "Save the dimension size for later usage when creating the Vertex AI Vector Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499ac47d-3386-487f-a730-58e2a102effe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "DIMENSIONS = len(question_embeddings[0])\n",
    "\n",
    "print(DIMENSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec035b91-fcad-49a3-87e1-ad94b6dd8dea",
   "metadata": {},
   "source": [
    "Sort questions in order of similarity. According to the [embedding documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings#colab_example_of_semantic_search_using_embeddings), the similarity of embeddings is calculated using the dot-product, with np.dot. Once you have the similarity score, sort the results and print them for inspection. 1 means very similar, 0 means very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ccf48c4-bd93-41cd-bda2-936071528720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query question = DI: Register-Resolve-Release when using child containers\n",
      "\t0: DI: Register-Resolve-Release when using child containers: 0.9999978110458627\n",
      "\t1: C# not releasing memory after task complete: 0.5136752460923943\n",
      "\t2: Embed xml into dll: 0.4803991893181705\n",
      "\t3: Load whole *ui file in an frame/widget of another *.ui file: 0.4545462072696377\n",
      "\t4: Using a 'using alias = class' with generic types?: 0.44325575692733843\n",
      "\t5: Returning values from MyBatis <insert> mapped methods: 0.4405694235804478\n",
      "\t6: How inefficient is passing Collections.unmodifiable* an instance which is already wrapped with Collections.unmodifiable*?: 0.4169665087870481\n",
      "\t7: Is a jbyteArray a jobject (i.e.: as a parameter to DeleteLocalRef)?: 0.3929884675899803\n",
      "\t8: Regex.Replace and String immutability: 0.3880198360882109\n",
      "\t9: PHP internationalization with intl: 0.3860386004774648\n",
      "\t10: Render List returned via JQuery: 0.3849918594436284\n",
      "\t11: Where to Store Encryption Keys MVC Application: 0.38287309031907313\n",
      "\t12: Autodiscover widgets for Django apps registered in settins.py: 0.381602263327151\n",
      "\t13: How to call an ASP.NET WebMethod in a UserControl (.ascx): 0.38152237600273614\n",
      "\t14: Using one css/js file: 0.3794957218423135\n",
      "\t15: Send file with skype4com in C#?: 0.37857736328437996\n",
      "\t16: Get single row result with Doctrine NativeQuery: 0.3757350959589837\n",
      "\t17: Create new element with doctrine entity manager?: 0.3747012171479602\n",
      "\t18: What is the best way to resolve a tree conflict with TortoiseSVN if I want to keep my local changes?: 0.3740287643546872\n",
      "\t19: pass request parameter value to class function and return value in classic asp: 0.37375727870085207\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "question_index = random.randint(0, 99)\n",
    "\n",
    "print(f\"Query question = {questions[question_index]}\")\n",
    "\n",
    "# Get similarity scores for each embedding by using dot-product.\n",
    "scores = np.dot(question_embeddings[question_index], question_embeddings.T)\n",
    "\n",
    "# Print top 20 matches\n",
    "for index, (question, score) in enumerate(\n",
    "    sorted(zip(questions, scores), key=lambda x: x[1], reverse=True)[:20]\n",
    "):\n",
    "    print(f\"\\t{index}: {question}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99838fd2-49d9-4a6a-919d-ee0840ad71f5",
   "metadata": {},
   "source": [
    "Save the embeddings in JSONL format. The data must be formatted in JSONL format, which means each embedding dictionary is written as an individual JSON object on its own line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e641cbc-986f-4ba5-9881-26907e577023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings directory: /var/tmp/tmpzx18w_a0\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temporary file to write embeddings to\n",
    "embeddings_file_path = Path(tempfile.mkdtemp())\n",
    "\n",
    "print(f\"Embeddings directory: {embeddings_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc06d3-376b-4c77-bafd-0c3eb51c98ae",
   "metadata": {},
   "source": [
    "Write embeddings in batches to prevent out-of-memory errors. Notice we are only using 5000 questions so that the embedding creation process and indexing is faster. The dataset contains more than 50,000 questions. This step will take around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31368a3d-c39d-4ce0-be67-270d4612bbb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fa3c6313b94e999e29b657b67ec121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunk of rows from BigQuery:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1847dc172574459d99ff8f1450cf00a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34155a4bfabf43acbb5b0807c5df4e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f5020880ea4e0283d9a3a26ee5c181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51db4b98e9ca41cc942945033de23605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97c09a541b947d2aed60e4b77055f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "\n",
    "BQ_NUM_ROWS = 5000\n",
    "BQ_CHUNK_SIZE = 1000\n",
    "BQ_NUM_CHUNKS = math.ceil(BQ_NUM_ROWS / BQ_CHUNK_SIZE)\n",
    "\n",
    "START_CHUNK = 0\n",
    "\n",
    "# Create a rate limit of 300 requests per minute. Adjust this depending on your quota.\n",
    "API_CALLS_PER_SECOND = 300 / 60\n",
    "# According to the docs, each request can process 5 instances per request\n",
    "ITEMS_PER_REQUEST = 5\n",
    "\n",
    "# Loop through each generated dataframe, convert\n",
    "for i, df in tqdm(\n",
    "    enumerate(\n",
    "        query_bigquery_chunks(\n",
    "            max_rows=BQ_NUM_ROWS, rows_per_chunk=BQ_CHUNK_SIZE, start_chunk=START_CHUNK\n",
    "        )\n",
    "    ),\n",
    "    total=BQ_NUM_CHUNKS - START_CHUNK,\n",
    "    position=-1,\n",
    "    desc=\"Chunk of rows from BigQuery\",\n",
    "):\n",
    "    # Create a unique output file for each chunk\n",
    "    chunk_path = embeddings_file_path.joinpath(\n",
    "        f\"{embeddings_file_path.stem}_{i+START_CHUNK}.json\"\n",
    "    )\n",
    "    with open(chunk_path, \"a\") as f:\n",
    "        id_chunk = df.id\n",
    "\n",
    "        # Convert batch to embeddings\n",
    "        is_successful, question_chunk_embeddings = encode_text_to_embedding_batched(\n",
    "            sentences=df.title_with_body.to_list(),\n",
    "            api_calls_per_second=API_CALLS_PER_SECOND,\n",
    "            batch_size=ITEMS_PER_REQUEST,\n",
    "        )\n",
    "\n",
    "        # Append to file\n",
    "        embeddings_formatted = [\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"id\": str(id),\n",
    "                    \"embedding\": [str(value) for value in embedding],\n",
    "                }\n",
    "            )\n",
    "            + \"\\n\"\n",
    "            for id, embedding in zip(id_chunk[is_successful], question_chunk_embeddings)\n",
    "        ]\n",
    "        f.writelines(embeddings_formatted)\n",
    "\n",
    "        # Delete the DataFrame and any other large data structures\n",
    "        del df\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467618c-403c-46ee-8854-9b56b4a2f113",
   "metadata": {},
   "source": [
    "# Upload embeddings to Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b397b-ed8d-47ce-a7fb-0455ba606bfe",
   "metadata": {},
   "source": [
    "Upload the text-embeddings to Cloud Storage, so that Vertex AI Vector Search can access them later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c4b34-6794-4fa0-8286-e2422a9eefc2",
   "metadata": {},
   "source": [
    "Define a bucket where you will store your embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b24fae1-3e6f-421c-9e3d-c1d90c344027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://{PROJECT_ID}-unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d62a63-428d-4b91-a86e-5849f9041b96",
   "metadata": {},
   "source": [
    "Create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8593b1f3-0e00-4d6c-b07a-b383d3d7bdfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-02-9c2eecad5f04-unique/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c232c-0baf-41f3-a335-8f2b95436f9b",
   "metadata": {},
   "source": [
    "Upload the training data to a Google Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d52791c-323a-4e09-a0ff-d0d7d7a0275c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///var/tmp/tmpzx18w_a0/tmpzx18w_a0_0.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmpzx18w_a0/tmpzx18w_a0_1.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmpzx18w_a0/tmpzx18w_a0_2.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmpzx18w_a0/tmpzx18w_a0_3.json [Content-Type=application/json]...\n",
      "Copying file:///var/tmp/tmpzx18w_a0/tmpzx18w_a0_4.json [Content-Type=application/json]...\n",
      "- [5/5 files][ 27.9 MiB/ 27.9 MiB] 100% Done                                    \n",
      "Operation completed over 5 objects/27.9 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "remote_folder = f\"{BUCKET_URI}/{embeddings_file_path.stem}/\"\n",
    "! gsutil -m cp -r {embeddings_file_path}/* {remote_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdeeb3a-fa32-439b-ae76-c7e55ebc65e2",
   "metadata": {},
   "source": [
    "# Create an Index in Vertex AI Vector Search for your embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97035853-fefc-491f-a430-12beb6fadb2e",
   "metadata": {},
   "source": [
    "Setup your index name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a15ea788-738f-4052-90b9-6b5e8e31658b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"stack_overflow\"\n",
    "DESCRIPTION = \"question titles and bodies from stackoverflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b33ba-37b7-4de2-b77c-deee1839f6c1",
   "metadata": {},
   "source": [
    "Create the index. \n",
    "Notice that the index reads the embeddings from the Cloud Storage bucket. \n",
    "The indexing process can take from 45 minutes up to 60 minutes. \n",
    "Wait for completion, and then proceed. You can open a different Google Cloud Console page, navigate to Vertex AI Vector search, and see how the index is being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c737f6af-1c8c-46dd-a6df-12d6842d8349",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/545248027730/locations/us-west1/indexes/6648183863208050688/operations/3743299981147111424\n",
      "MatchingEngineIndex created. Resource name: projects/545248027730/locations/us-west1/indexes/6648183863208050688\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/545248027730/locations/us-west1/indexes/6648183863208050688')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)\n",
    "\n",
    "DIMENSIONS = 768\n",
    "\n",
    "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=remote_folder,\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=150,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=80,\n",
    "    description=DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dbc3cf-33c1-4d42-b53f-b60020908213",
   "metadata": {},
   "source": [
    "Reference the index name to make sure it got created successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2b21419-6e10-4125-8249-37c128becd09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/545248027730/locations/us-west1/indexes/6648183863208050688'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292020c-93e5-4f5e-ba9d-2e71df458819",
   "metadata": {},
   "source": [
    "Using the resource name, you can retrieve an existing MatchingEngineIndex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aec57ec-2ac6-47a7-a094-d30212e469ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cefda2-70ed-4953-90f0-89b5e19ac1db",
   "metadata": {},
   "source": [
    "Create an IndexEndpoint so that it can be accessed via an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1f60bde-a1fa-4708-9177-37e1b482503b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/545248027730/locations/us-west1/indexEndpoints/2908542507002363904/operations/8625201977216729088\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/545248027730/locations/us-west1/indexEndpoints/2908542507002363904\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/545248027730/locations/us-west1/indexEndpoints/2908542507002363904')\n"
     ]
    }
   ],
   "source": [
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    description=DISPLAY_NAME,\n",
    "    public_endpoint_enabled=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef99756-63ea-4eb3-972c-c9679e471f23",
   "metadata": {},
   "source": [
    "Deploy your index to the created endpoint. This can take up to 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7aad519a-5a5a-4e90-83bc-314f1df52848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/545248027730/locations/us-west1/indexEndpoints/2908542507002363904\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/545248027730/locations/us-west1/indexEndpoints/2908542507002363904/operations/2257112104114847744\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/545248027730/locations/us-west1/indexEndpoints/2908542507002363904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"deployed_index_id_unique\"\n",
       "index: \"projects/545248027730/locations/us-west1/indexes/6648183863208050688\"\n",
       "create_time {\n",
       "  seconds: 1748425073\n",
       "  nanos: 774808000\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1748426978\n",
       "  nanos: 935213000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEPLOYED_INDEX_ID = \"deployed_index_id_unique\"\n",
    "\n",
    "DEPLOYED_INDEX_ID\n",
    "\n",
    "\n",
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61dbab-38c8-4800-97ed-d5388b58e329",
   "metadata": {},
   "source": [
    "---\n",
    "Verify number of declared items matches the number of embeddings. \n",
    "\n",
    "Each IndexEndpoint can have multiple indexes deployed to it. \n",
    "\n",
    "For each index, you can retrieve the number of deployed vectors using the index_endpoint._gca_resource.index_stats.vectors_count. \n",
    "\n",
    "The numbers may not match exactly due to potential rate-limiting failures incurred when using the embedding service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f6eae0-f1d6-46ac-8483-369fe171333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_vectors = sum(\n",
    "    aiplatform.MatchingEngineIndex(\n",
    "        deployed_index.index\n",
    "    )._gca_resource.index_stats.vectors_count\n",
    "    for deployed_index in my_index_endpoint.deployed_indexes\n",
    ")\n",
    "\n",
    "print(f\"Expected: {BQ_NUM_ROWS}, Actual: {number_of_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23152926-a1bd-4ac5-a6bd-38d083deef4a",
   "metadata": {},
   "source": [
    "# Create online queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44746e2-79ea-4cc8-ba0b-a6bfa42d5f6e",
   "metadata": {},
   "source": [
    "After you build your indexes, you may query against the deployed index to find nearest neighbors.\n",
    "\n",
    "Note: For the `DOT_PRODUCT_DISTANCE` distance type, the \"distance\" property returned with each MatchNeighbor actually refers to the similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb51529-9eab-44e2-8a5c-e504b94e8a8d",
   "metadata": {},
   "source": [
    "Create an embedding for a test question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb19c5-b96f-4020-a218-30a7bda7d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = encode_texts_to_embeddings(sentences=[\"Install GPU for Tensorflow\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f874b63-ea13-4c86-9543-7935b56c06d1",
   "metadata": {},
   "source": [
    "Test the query to retrieve the similar embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad328c15-0e93-4d9c-9955-720adb6fe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NEIGHBOURS = 10\n",
    "\n",
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "    queries=test_embeddings,\n",
    "    num_neighbors=NUM_NEIGHBOURS,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6a955-94eb-44c6-97d5-fa2afb94e586",
   "metadata": {},
   "source": [
    "Verify that the retrieved results are relevant by checking the StackOverflow links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab69e8-e876-446c-a0cc-5342dbc0b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_index, neighbor in enumerate(response[0]):\n",
    "    print(f\"https://stackoverflow.com/questions/{neighbor.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f5b05-dcae-4eae-a58f-3baf5c43676c",
   "metadata": {},
   "source": [
    "# Clean up the Google Cloud environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4416021-3397-4e25-a132-789e23e6d9c6",
   "metadata": {},
   "source": [
    "To clean up all Google Cloud resources used in this project, you can delete the Google Cloud project you used for the lab. \n",
    "You can also manually delete resources that you created by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb737ec-21e1-4fda-aece-b8bc5ed450ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "delete_bucket = False\n",
    "\n",
    "# Force undeployment of indexes and delete endpoint\n",
    "my_index_endpoint.delete(force=True)\n",
    "\n",
    "# Delete indexes\n",
    "tree_ah_index.delete()\n",
    "\n",
    "if delete_bucket or os.getenv(\"IS_TESTING\"):\n",
    "    ! gsutil rm -rf {BUCKET_URI}"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
