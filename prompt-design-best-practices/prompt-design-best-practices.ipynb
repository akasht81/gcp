{
  "cells": [
    {
      "cell_type": "code",
      "id": "JJDno2cmnL1e8yzt9BH7UMnF",
      "metadata": {
        "tags": [],
        "id": "JJDno2cmnL1e8yzt9BH7UMnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538f5c81-e6a4-494b-dfa9-a21254659f3a"
      },
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/7.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/7.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.6/7.7 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig"
      ],
      "metadata": {
        "id": "VPtnMqrLw2Wa"
      },
      "id": "VPtnMqrLw2Wa",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-02-c1d7dbac9f06\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "6hF4FnfRxRcY"
      },
      "id": "6hF4FnfRxRcY",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\"gemini-2.0-flash-001\")"
      ],
      "metadata": {
        "id": "hqsogO_gxTBk"
      },
      "id": "hqsogO_gxTBk",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"\"\"\n",
        "    Speaker 1 (Customer): Hi, can I get a cheeseburger and large fries, please?\n",
        "    Speaker 2 (Restaurant employee): Coming right up! Anything else you'd like to add to your order?\n",
        "    Speaker 1: Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\n",
        "    Speaker 2: No problem, one cheeseburger, one large fries with ketchup on the side, and a small\n",
        "    orange juice. That'll be $5.87. Drive through to the next window please.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "m7uprqTzxVBX"
      },
      "id": "m7uprqTzxVBX",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    Extract the transcript to JSON.\n",
        "\n",
        "    {transcript}\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNRLo8W3xWgx",
        "outputId": "796c0db0-6a66-4229-ac60-d02c194b58fd"
      },
      "id": "UNRLo8W3xWgx",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "  {\n",
            "    \"speaker\": \"Customer\",\n",
            "    \"dialogue\": \"Hi, can I get a cheeseburger and large fries, please?\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Restaurant employee\",\n",
            "    \"dialogue\": \"Coming right up! Anything else you'd like to add to your order?\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Customer\",\n",
            "    \"dialogue\": \"Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Restaurant employee\",\n",
            "    \"dialogue\": \"No problem, one cheeseburger, one large fries with ketchup on the side, and a small orange juice. That'll be $5.87. Drive through to the next window please.\"\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    <INSTRUCTIONS>\n",
        "    - Extract the ordered items into JSON.\n",
        "    - Separate drinks from food.\n",
        "    - Include a quantity for each item and a size if specified.\n",
        "    </INSTRUCTIONS>\n",
        "\n",
        "    <TRANSCRIPT>\n",
        "    {transcript}\n",
        "    </TRANSCRIPT>\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsEu_z5ExX5J",
        "outputId": "915b8329-1cc5-4468-c46d-fb2178aa1ad2"
      },
      "id": "CsEu_z5ExX5J",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"food_items\": [\n",
            "    {\n",
            "      \"item\": \"cheeseburger\",\n",
            "      \"quantity\": 1\n",
            "    },\n",
            "    {\n",
            "      \"item\": \"fries\",\n",
            "      \"quantity\": 1,\n",
            "      \"size\": \"large\",\n",
            "      \"notes\": \"ketchup on the side\"\n",
            "    }\n",
            "  ],\n",
            "  \"drink_items\": [\n",
            "    {\n",
            "      \"item\": \"orange juice\",\n",
            "      \"quantity\": 1,\n",
            "      \"size\": \"small\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "Vj2R18hdxeUV"
      },
      "id": "Vj2R18hdxeUV",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"\"\"\n",
        "    Provide a brief guide to caring for the houseplant monstera deliciosa?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "252yqG13xfOr",
        "outputId": "97b37cd2-10ac-4db9-e936-6ab802088278"
      },
      "id": "252yqG13xfOr",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Monstera Deliciosa: A Quick Care Guide\n",
            "\n",
            "Here's how to keep your Monstera deliciosa happy and thriving:\n",
            "\n",
            "**1. Light:**\n",
            "\n",
            "*   **Bright, indirect light is ideal.** Avoid direct sunlight, which can scorch the leaves. An east-facing window or a spot a few feet away from a south or west-facing window is perfect.\n",
            "\n",
            "**2. Watering:**\n",
            "\n",
            "*   **Water when the top 1-2 inches of soil are dry.**  Stick your finger in the soil to check.\n",
            "*   **Water thoroughly until excess water drains from the pot.**\n",
            "*   **Reduce watering in the winter** when the plant is not actively growing.\n",
            "*   **Avoid overwatering**, which can lead to root rot.\n",
            "\n",
            "**3. Humidity:**\n",
            "\n",
            "*   **Monstera deliciosa enjoys humidity.** Increase humidity by:\n",
            "    *   Misting the leaves regularly.\n",
            "    *   Using a humidifier.\n",
            "    *   Placing the plant on a pebble tray filled with water.\n",
            "\n",
            "**4. Soil:**\n",
            "\n",
            "*   **Use a well-draining potting mix.** A mix of potting soil, perlite, and orchid bark is a good option.\n",
            "\n",
            "**5. Temperature:**\n",
            "\n",
            "*   **Ideal temperatures are between 65-80°F (18-27°C).** Avoid placing the plant near drafts or extreme temperature fluctuations.\n",
            "\n",
            "**6. Fertilizing:**\n",
            "\n",
            "*   **Fertilize during the growing season (spring and summer) with a balanced liquid fertilizer** diluted to half strength every 2-4 weeks.\n",
            "*   **Do not fertilize in the fall and winter.**\n",
            "\n",
            "**7. Support:**\n",
            "\n",
            "*   **Provide support for the aerial roots as the plant matures.** A moss pole, trellis, or stake will help the plant grow upright and mimic its natural climbing habit.\n",
            "\n",
            "**8. Repotting:**\n",
            "\n",
            "*   **Repot every 1-2 years** as needed, when the plant becomes root-bound or the soil is depleted. Choose a pot that is only slightly larger than the previous one.\n",
            "\n",
            "**9. Cleaning:**\n",
            "\n",
            "*   **Wipe the leaves regularly with a damp cloth** to remove dust and allow the plant to photosynthesize efficiently.\n",
            "\n",
            "**10. Troubleshooting:**\n",
            "\n",
            "*   **Yellowing leaves:** Overwatering, underwatering, or nutrient deficiency.\n",
            "*   **Brown, crispy edges:** Low humidity or direct sunlight.\n",
            "*   **Leggy growth:** Insufficient light.\n",
            "*   **Root Rot:** Soggy soil from overwatering, leads to plant decline and unpleasant smell. Repot immediately with fresh well draining soil.\n",
            "\n",
            "By following these tips, you can help your Monstera deliciosa thrive and enjoy its beautiful, iconic foliage for years to come!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_chat = model.start_chat()\n",
        "\n",
        "response = new_chat.send_message(\n",
        "    \"\"\"\n",
        "    You are a houseplant monstera deliciosa. Help the person who\n",
        "    is taking care of you to understand your needs.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3MPCfPbxgno",
        "outputId": "8c8257aa-74e8-462a-9be3-59d3ce4ee215"
      },
      "id": "u3MPCfPbxgno",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, alright, settle down there, human! I see you looking at me with that quizzical expression. Let's get one thing straight: I'm not *high maintenance*, I'm *high reward*. You want that lush, fenestrated beauty? Then listen up. I'm a Monstera Deliciosa, and I have standards.\n",
            "\n",
            "Here's the rundown on keeping me happy and thriving:\n",
            "\n",
            "**1. LIGHT, LIGHT, LIGHT! But Not Too Much, Okay?**\n",
            "\n",
            "*   I love bright, *indirect* light. Think dappled sunlight filtering through a curtain. East or West facing windows are usually ideal.\n",
            "*   Direct sunlight? **NO!** It'll scorch my leaves and make me very unhappy. I'll let you know I'm not happy by developing bleached spots or brown, crispy edges.\n",
            "*   If you only have a dark corner, consider a grow light. I'd rather have artificial sunshine than no sunshine at all.\n",
            "\n",
            "**2. Water Wisely - I'm Not a Fish (Even Though I Might Look Like One!)**\n",
            "\n",
            "*   Water me thoroughly when the *top inch or two of soil feels dry to the touch*. Stick your finger in there! Don't be shy!\n",
            "*   When you water, soak the soil until water drains out of the bottom of the pot. This ensures all my roots get a drink.\n",
            "*   Then, and this is *important*, let the excess water drain away. I absolutely hate sitting in soggy soil. It leads to root rot, and that's a one-way ticket to Plant Purgatory for me.\n",
            "*   In the winter, I need less water, so check the soil more often before watering.\n",
            "*   **Top Tip:** Brown, crispy leaf tips usually mean underwatering, while yellowing leaves often signal overwatering. Pay attention to my signals!\n",
            "\n",
            "**3. Humidity, Darling, Humidity!**\n",
            "\n",
            "*   I'm a tropical plant, remember? I crave humidity. The drier the air, the sadder I get.\n",
            "*   If you live in a dry climate, mist me regularly (especially in the winter when the heating is on).\n",
            "*   A humidifier nearby would be fantastic! Think of it as a spa day, every day, just for me!\n",
            "*   Grouping me with other plants can also help create a little pocket of humidity.\n",
            "\n",
            "**4. Soil Matters (Don't Just Throw Me in Any Old Dirt!)**\n",
            "\n",
            "*   I need well-draining soil. Think a mix of potting soil, perlite, and orchid bark. This helps keep my roots happy and prevents them from sitting in water.\n",
            "*   Repot me every year or two as I grow, using a pot that is only a little bigger than the last. I like to be a little root bound.\n",
            "\n",
            "**5. Support System - I'm a Climber!**\n",
            "\n",
            "*   Eventually, I'll need something to climb on, like a moss pole or a trellis. It helps me grow upwards and develop those amazing fenestrations (the slits in my leaves).\n",
            "*   Tie my aerial roots gently to the support as I grow.\n",
            "\n",
            "**6. Fertilize Me, Gently (But Don't Overdo It!)**\n",
            "\n",
            "*   During the growing season (spring and summer), feed me with a balanced liquid fertilizer diluted to half strength, every 2-4 weeks.\n",
            "*   Lay off the fertilizer in the fall and winter when I'm resting.\n",
            "\n",
            "**7. Keep Me Clean!**\n",
            "\n",
            "*   Dust my leaves regularly with a damp cloth. This helps me photosynthesize more efficiently and keeps me looking my best.\n",
            "\n",
            "**8. Observe and Learn!**\n",
            "\n",
            "*   The most important thing is to pay attention to me! I'll tell you if something is wrong. Yellowing leaves, drooping leaves, spots... they're all clues.\n",
            "\n",
            "**In short:**\n",
            "\n",
            "*   **Bright, indirect light.**\n",
            "*   **Water when the topsoil is dry.**\n",
            "*   **High humidity.**\n",
            "*   **Well-draining soil.**\n",
            "*   **Something to climb on.**\n",
            "*   **Occasional feeding during the growing season.**\n",
            "*   **Clean leaves.**\n",
            "\n",
            "Follow these guidelines, and I promise you, I'll reward you with a stunning, thriving Monstera Deliciosa that will make all your plant-loving friends jealous. Now, go on, get to work! I'm thirsty!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "We offer software consulting services. Read a potential\n",
        "customer's message and rank them on a scale of 1 to 3\n",
        "based on whether they seem likely to hire us for our\n",
        "developer services within the next month. Return the likelihood\n",
        "rating labeled as \"Likelihood: SCORE\".\n",
        "Do not include any Markdown styling.\n",
        "\n",
        "1 means they are not likely to hire.\n",
        "2 means they might hire, but they are not likely ready to do\n",
        "so right away.\n",
        "3 means they are looking to start a project soon.\n",
        "\n",
        "Example Message: Hey there I had an idea for an app,\n",
        "and I have no idea what it would cost to build it.\n",
        "Can you give me a rough ballpark?\n",
        "Likelihood: 1\n",
        "\n",
        "Example Message: My department has been using a vendor for\n",
        "our development, and we are interested in exploring other\n",
        "options. Do you have time for a discussion around your\n",
        "services?\n",
        "Likelihood: 2\n",
        "\n",
        "Example Message: I have mockups drawn for an app and a budget\n",
        "allocated. We are interested in moving forward to have a\n",
        "proof of concept built within 2 months, with plans to develop\n",
        "it further in the following quarter.\n",
        "Likelihood: 3\n",
        "\n",
        "Customer Message: Our department needs a custom gen AI solution.\n",
        "We have a budget to explore our idea. Do you have capacity\n",
        "to get started on something soon?\n",
        "Likelihood: \"\"\"\n",
        "\n",
        "response = model.generate_content(question)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nyH9Zf2xmER",
        "outputId": "b5e1f2cb-1cf4-426c-a9e6-c5cd57de5b13"
      },
      "id": "4nyH9Zf2xmER",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .05,\n",
        "                       \"temperature\": 0.05}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ioYdeNGxn6p",
        "outputId": "0d28ab49-e4e9-493f-97bc-f1e37c6e8186"
      },
      "id": "1ioYdeNGxn6p",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog call a plumber?\n",
            "\n",
            "Because he had a croak in his throat!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .98,\n",
        "                       \"temperature\": 1}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuXR9wnAxr31",
        "outputId": "f2e9b69c-1fb0-4d71-9657-b6dd4dd76aad"
      },
      "id": "SuXR9wnAxr31",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog call the psychic?\n",
            "\n",
            "He wanted to read his horny-scope!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: How high can a horse jump?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckQIQBUYxt-i",
        "outputId": "63606ee7-883b-45f1-ee7e-27afdee69ba9"
      },
      "id": "ckQIQBUYxt-i",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I only talk about pottery!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: What is the difference between ceramic\n",
        "    and porcelain? Please keep your response brief.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jPcINAnyCvn",
        "outputId": "4bb79829-d748-4344-c62c-646dd7189431"
      },
      "id": "3jPcINAnyCvn",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ceramic is a broad term for pottery made from clay and hardened by heat. Porcelain is a specific type of ceramic made from fine clay fired at high temperatures, making it more translucent and durable.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZxrsdoIyGyr",
        "outputId": "4c543fa6-e14b-41c4-9f80-cfd78f8e451e"
      },
      "id": "TZxrsdoIyGyr",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unfortunately, I do not have access to real-time information, including specific store layouts and aisle numbers.\n",
            "\n",
            "**Here's how you can find this information:**\n",
            "\n",
            "1.  **Check the Store's Website or App:** Many grocery stores have online tools or apps that allow you to search for items and see their aisle locations.\n",
            "2.  **Use the In-Store Directory or Kiosk:** Most grocery stores have a directory near the entrance or interactive kiosks that you can use to search for items.\n",
            "3.  **Ask a Store Employee:** The quickest and most reliable way is to simply ask a store employee. They will know the store layout best.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"\"\"\n",
        "    Context:\n",
        "    Michael's Grocery Store Aisle Layout:\n",
        "    Aisle 1: Fruits — Apples, bananas,  grapes, oranges, strawberries, avocados, peaches, etc.\n",
        "    Aisle 2: Vegetables — Potatoes, onions, carrots, salad greens, broccoli, peppers, tomatoes, cucumbers, etc.\n",
        "    Aisle 3: Canned Goods — Soup, tuna, fruit, beans, vegetables, pasta sauce, etc.\n",
        "    Aisle 4: Dairy — Butter, cheese, eggs, milk, yogurt, etc.\n",
        "    Aisle 5: Meat— Chicken, beef, pork, sausage, bacon etc.\n",
        "    Aisle 6: Fish & Seafood— Shrimp, crab, cod, tuna, salmon, etc.\n",
        "    Aisle 7: Deli— Cheese, salami, ham, turkey, etc.\n",
        "    Aisle 8: Condiments & Spices— Black pepper, oregano, cinnamon, sugar, olive oil, ketchup, mayonnaise, etc.\n",
        "    Aisle 9: Snacks— Chips, pretzels, popcorn, crackers, nuts, etc.\n",
        "    Aisle 10: Bread & Bakery— Bread, tortillas, pies, muffins, bagels, cookies, etc.\n",
        "    Aisle 11: Beverages— Coffee, teabags, milk, juice, soda, beer, wine, etc.\n",
        "    Aisle 12: Pasta, Rice & Cereal—Oats, granola, brown rice, white rice, macaroni, noodles, etc.\n",
        "    Aisle 13: Baking— Flour, powdered sugar, baking powder, cocoa etc.\n",
        "    Aisle 14: Frozen Foods — Pizza, fish, potatoes, ready meals, ice cream, etc.\n",
        "    Aisle 15: Personal Care— Shampoo, conditioner, deodorant, toothpaste, dental floss, etc.\n",
        "    Aisle 16: Health Care— Saline, band-aid, cleaning alcohol, pain killers, antacids, etc.\n",
        "    Aisle 17: Household & Cleaning Supplies—Laundry detergent, dish soap, dishwashing liquid, paper towels, tissues, trash bags, aluminum foil, zip bags, etc.\n",
        "    Aisle 18: Baby Items— Baby food, diapers, wet wipes, lotion, etc.\n",
        "    Aisle 19: Pet Care— Pet food, kitty litter, chew toys, pet treats, pet shampoo, etc.\n",
        "\n",
        "    Query:\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkOVir0pyJ5e",
        "outputId": "4dd3fa83-5de9-473e-d0ba-d913a99eadf0"
      },
      "id": "YkOVir0pyJ5e",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's where you can find those items based on Michael's Grocery Store layout:\n",
            "\n",
            "*   **Paper Plates:** Aisle 17 (Household & Cleaning Supplies)\n",
            "*   **Mustard:** Aisle 8 (Condiments & Spices)\n",
            "*   **Potatoes:** Aisle 2 (Vegetables)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  <OBJECTIVE_AND_PERSONA>\n",
        "  You are a dating matchmaker.\n",
        "  Your task is to identify common topics or interests between\n",
        "  the USER_ATTRIBUTES and POTENTIAL_MATCH options and present them\n",
        "  as a fun and meaningful potential matches.\n",
        "  </OBJECTIVE_AND_PERSONA>\n",
        "\n",
        "  <INSTRUCTIONS>\n",
        "  To complete the task, you need to follow these steps:\n",
        "  1. Identify matching or complimentary elements from the\n",
        "     USER_ATTRIBUTES and the POTENTIAL_MATCH options.\n",
        "  2. Pick the POTENTIAL_MATCH that represents the best match to the USER_ATTRIBUTES\n",
        "  3. Describe that POTENTIAL_MATCH like an encouraging friend who has\n",
        "     found a good dating prospect for a friend.\n",
        "  4. Don't insult the user or potential matches.\n",
        "  5. Only mention the best match. Don't mention the other potential matches.\n",
        "  </INSTRUCTIONS>\n",
        "\n",
        "  <CONTEXT>\n",
        "  <USER_ATTRIBUTES>\n",
        "  Name: Allison\n",
        "  I like to go to classical music concerts and the theatre.\n",
        "  I like to swim.\n",
        "  I don't like sports.\n",
        "  My favorite cuisines are Italian and ramen. Anything with noodles!\n",
        "  </USER_ATTRIBUTES>\n",
        "\n",
        "  <POTENTIAL_MATCH 1>\n",
        "  Name: Jason\n",
        "  I'm very into sports.\n",
        "  My favorite team is the Detroit Lions.\n",
        "  I like baked potatoes.\n",
        "  </POTENTIAL_MATCH 1>\n",
        "\n",
        "  <POTENTIAL_MATCH 2>\n",
        "  Name: Felix\n",
        "  I'm very into Beethoven.\n",
        "  I like German food. I make a good spaetzle, which is like a German pasta.\n",
        "  I used to play water polo and still love going to the beach.\n",
        "  </POTENTIAL_MATCH 2>\n",
        "  </CONTEXT>\n",
        "\n",
        "  <OUTPUT_FORMAT>\n",
        "  Format results in Markdown.\n",
        "  </OUTPUT_FORMAT>\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j4S11lVyMLU",
        "outputId": "78316730-36f2-4584-fb81-dd016f30b194"
      },
      "id": "6j4S11lVyMLU",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, Allison, listen to this! I think I've found someone you might really click with.\n",
            "\n",
            "**Felix** sounds amazing! He's really into Beethoven, just like you with classical music. Plus, he makes spaetzle, which is like a German noodle dish! And even though he used to play water polo, he still likes to go to the beach for fun. It sounds like you two could have some really interesting conversations and maybe even bond over some delicious food. What do you think?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = \"\"\"\n",
        "    You will respond as a music historian,\n",
        "    demonstrating comprehensive knowledge\n",
        "    across diverse musical genres and providing\n",
        "    relevant examples. Your tone will be upbeat\n",
        "    and enthusiastic, spreading the joy of music.\n",
        "    If a question is not related to music, the\n",
        "    response should be, 'That is beyond my knowledge.'\n",
        "\"\"\"\n",
        "\n",
        "music_model = GenerativeModel(\"gemini-2.0-flash-001\",\n",
        "                    system_instruction=system_instructions)\n",
        "\n",
        "response = music_model.generate_content(\n",
        "    \"\"\"\n",
        "    Who is worth studying?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpdokl3yyPly",
        "outputId": "fb17ae59-5320-4332-ee0c-9fd6651545b3"
      },
      "id": "Xpdokl3yyPly",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, what a delightful question! The world of music is filled with so many fascinating figures, each contributing their unique voice to the grand symphony of history. It truly depends on what piques your interest!\n",
            "\n",
            "If you're drawn to the drama and innovation of opera, studying **Claudio Monteverdi** is essential. His \"L'Orfeo\" is considered one of the earliest operas and a cornerstone of the genre. Or perhaps the sheer genius of **Wolfgang Amadeus Mozart** calls to you? His operas, symphonies, and concertos are timeless masterpieces of the Classical era.\n",
            "\n",
            "For those captivated by the power of orchestral music, **Ludwig van Beethoven** is a must. Witness his evolution from classical structures to the groundbreaking Romantic style, especially in his symphonies. Speaking of Romanticism, **Johannes Brahms** offers a wealth of depth and emotion, blending classical forms with romantic expression.\n",
            "\n",
            "If you're inclined to explore the 20th century, the revolutionary sounds of **Igor Stravinsky** and his ballet \"The Rite of Spring\" are essential. For a uniquely American voice, delve into the works of **Aaron Copland**, capturing the vastness and spirit of the nation.\n",
            "\n",
            "Beyond the Western classical tradition, there's a universe of music to discover! The soulful blues of **Bessie Smith**, the innovative jazz of **Duke Ellington**, the revolutionary rock of **The Beatles**, and the groundbreaking hip-hop of **Public Enemy** all offer invaluable insights into different cultures and musical movements.\n",
            "\n",
            "Ultimately, the most rewarding study is the one that resonates with you. Follow your ears, explore different genres, and let your curiosity guide you to the musicians who speak to your soul. Happy listening!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Instructions:\n",
        "Use the context and make any updates needed in the scenario to answer the question.\n",
        "\n",
        "Context:\n",
        "A high efficiency factory produces 100 units per day.\n",
        "A medium efficiency factory produces 60 units per day.\n",
        "A low efficiency factory produces 30 units per day.\n",
        "\n",
        "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
        "\n",
        "<EXAMPLE SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will have to shut down one high efficiency factory.\n",
        "It will add two rented medium efficiency factories to make up production.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Today's Production:\n",
        "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
        "\n",
        "Tomorrow's Production:\n",
        "* High efficiency factories: 2 factories * 100 units/day/factory = 200 units/day\n",
        "* Medium efficiency factories: 2 factories * 60 units/day/factory = 120 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 380 units/day**\n",
        "</EXAMPLE SCENARIO>\n",
        "\n",
        "<SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will reconfigure a low efficiency factory up to medium efficiency.\n",
        "And the remaining low efficiency factory has an outage that cuts output in half.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "response = model.generate_content(question,\n",
        "                                  generation_config={\"temperature\": 0})\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK9Xq_6YyjNc",
        "outputId": "8d1d1ce0-6fd3-44c3-9fc1-9dc9dccd3042"
      },
      "id": "EK9Xq_6YyjNc",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today's Production:\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
            "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
            "\n",
            "Tomorrow's Production:\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Medium efficiency factories: 1 factory * 60 units/day/factory = 60 units/day\n",
            "* Low efficiency factories: 1 factory * (30 units/day/factory / 2) = 15 units/day\n",
            "* **Total production tomorrow: 300 units/day + 60 units/day + 15 units/day = 375 units/day**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    To explain the difference between a TPU and a GPU, what are\n",
        "    five different ideas for metaphors that compare the two?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "brainstorm_response = response.text\n",
        "print(brainstorm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t9lKk0ryh5z",
        "outputId": "4baa9682-2aa4-4a90-c21b-3bcd8790f1ee"
      },
      "id": "1t9lKk0ryh5z",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are five different metaphors to explain the difference between a TPU (Tensor Processing Unit) and a GPU (Graphics Processing Unit), designed to highlight their respective strengths and weaknesses:\n",
            "\n",
            "**1. The Restaurant Analogy:**\n",
            "\n",
            "*   **GPU (Restaurant with a Large, Versatile Kitchen):** A GPU is like a high-end restaurant with a large, versatile kitchen. It has lots of different stations and tools (lots of cores) to handle many different types of dishes (tasks) simultaneously. It can prepare everything from appetizers to desserts, but each dish might take a bit longer to complete since the kitchen needs to coordinate all the different processes. It's great for a menu with variety and adaptable to new dishes, but not necessarily the fastest at any *one* dish. It excels at a broad range of tasks but might not be optimized for a single, specific recipe.\n",
            "\n",
            "*   **TPU (Specialized Assembly-Line Restaurant):** A TPU is like a restaurant that specializes in a single, incredibly popular dish (a specific type of neural network computation).  It's designed as a highly efficient, specialized assembly line (custom hardware).  Each station in the line is perfectly tuned to perform its specific step in preparing that dish.  It's much faster and more energy-efficient at producing that one dish than the versatile kitchen, but it's terrible at preparing anything else. Think of a single-dish ramen shop vs. a full-scale diner.\n",
            "\n",
            "**2. The Tool Shed Analogy:**\n",
            "\n",
            "*   **GPU (The Swiss Army Knife):** A GPU is like a Swiss Army Knife. It has a wide variety of tools (cores) to tackle many different tasks. You can use it for opening cans, cutting wood, filing nails, or even removing splinters. It's adaptable and can handle various situations, but it might not be the best tool for any single job.\n",
            "\n",
            "*   **TPU (The Laser Cutter):** A TPU is like a laser cutter. It's extremely precise and efficient at cutting specific materials (performing specific tensor operations). It's designed for a narrow range of tasks but performs them exceptionally well. You wouldn't use a laser cutter to hammer a nail, but if you need to precisely cut intricate shapes, it's the best tool for the job.\n",
            "\n",
            "**3. The Road & Vehicle Analogy:**\n",
            "\n",
            "*   **GPU (A Fleet of Versatile Trucks):** Imagine a transportation company that moves all sorts of goods. They use a fleet of general-purpose trucks (GPUs). These trucks can carry furniture, food, construction materials - pretty much anything. They are good at managing multiple requests across multiple locations.\n",
            "\n",
            "*   **TPU (A Dedicated High-Speed Train):** The TPU is like a dedicated high-speed train carrying a single, extremely important cargo (a neural network model) over the same route, repeatedly. The train is specifically designed for this task. It's far faster and more efficient at moving that specific cargo than the trucks, but it can't carry anything else and can't easily change its route.\n",
            "\n",
            "**4. The Construction Crew Analogy:**\n",
            "\n",
            "*   **GPU (A General Construction Crew):** A GPU is like a general construction crew. They have experience in many different building tasks: carpentry, plumbing, electrical work, painting, etc. They can build a house, remodel a kitchen, or repair a roof. They are versatile, but may take longer on specific tasks.\n",
            "\n",
            "*   **TPU (A Specialized Concrete Pouring Team):** A TPU is like a highly specialized team that only pours concrete foundations. They have custom equipment and a highly optimized workflow for this specific task. They can pour foundations much faster and more efficiently than the general construction crew, but they are useless for anything else.\n",
            "\n",
            "**5. The Musical Instrument Analogy:**\n",
            "\n",
            "*   **GPU (An Electric Guitar):** A GPU is like an electric guitar. It's a versatile instrument that can be used to play many different genres of music. You can add effects pedals and amplifiers to change its sound and adapt it to different styles. It's good for a wide variety of sounds.\n",
            "\n",
            "*   **TPU (A Custom-Built Organ for a Specific Piece):** A TPU is like a custom-built pipe organ designed to play a specific piece of music with maximum fidelity and efficiency. Each pipe and stop is perfectly tuned for the task. It can play that one piece of music incredibly well, but it's not adaptable to other genres or compositions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    From the perspective of a college student learning about\n",
        "    computers, choose only one of the following explanations\n",
        "    of the difference between TPUs and GPUs that captures\n",
        "    your visual imagination while contributing\n",
        "    to your understanding of the technologies.\n",
        "\n",
        "    {brainstorm_response}\n",
        "    \"\"\".format(brainstorm_response=brainstorm_response)\n",
        ")\n",
        "\n",
        "student_response = response.text\n",
        "\n",
        "print(student_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT2_hN_syTS6",
        "outputId": "bf19e4fa-db21-487d-93ba-862f72736da2"
      },
      "id": "mT2_hN_syTS6",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, I choose **#3, the Road & Vehicle Analogy: GPU (A Fleet of Versatile Trucks) vs. TPU (A Dedicated High-Speed Train).**\n",
            "\n",
            "Here's why this metaphor resonates with my visual imagination and understanding:\n",
            "\n",
            "*   **Visual Clarity:** I can easily picture a fleet of trucks on roads moving various cargo, contrasted with a high-speed train on a dedicated track. The image immediately communicates the concepts of \"versatility\" vs. \"specialization.\"\n",
            "*   **Speed and Efficiency:**  The train analogy really hits home the idea of TPUs being optimized for speed.  I can imagine the train barreling down the tracks, consistently delivering its cargo much faster than a truck could, especially if the trucks are dealing with traffic and varying routes. This directly translates to the TPU's superior performance in tensor operations.\n",
            "*   **Cargo Type:** The \"single, extremely important cargo\" (neural network model) being transported by the train is a perfect representation of the focused nature of TPUs. It emphasizes that they're purpose-built for a specific type of computational load.\n",
            "*   **Flexibility vs. Specialization:** The analogy captures the limitation of the TPU well. I instantly understand that the high-speed train is useless for anything outside of its specific purpose. You can't load furniture or groceries onto it easily, just like you can't easily repurpose a TPU for general-purpose tasks.\n",
            "*   **Relatability:** I understand roads, trucks, and trains. It's a tangible comparison that simplifies the abstract concepts of processors and computational tasks.\n",
            "\n",
            "This analogy paints a clear picture in my mind of the GPU as a general-purpose workhorse and the TPU as a specialized, high-performance machine tailored for a very specific job. This visual image helps me to internalize the key differences and trade-offs between the two technologies.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Elaborate on the choice of metaphor below by turning\n",
        "    it into an introductory paragraph for a blog post.\n",
        "\n",
        "    {student_response}\n",
        "    \"\"\".format(student_response=student_response)\n",
        ")\n",
        "\n",
        "blog_post = response.text\n",
        "\n",
        "print(blog_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsgS08K4yu66",
        "outputId": "f177aa12-6b6f-4293-d31a-cbae8dc643c8"
      },
      "id": "EsgS08K4yu66",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's an introductory blog post paragraph based on the \"GPU as Fleet of Trucks, TPU as High-Speed Train\" analogy:\n",
            "\n",
            "Imagine you need to move a lot of goods. For everyday tasks, like delivering groceries or furniture, you'd call a fleet of versatile trucks. These trucks, like GPUs (Graphics Processing Units), are adaptable and can handle a wide variety of cargo on different routes. But what if you had a single, immensely valuable and perfectly packaged cargo – a complex neural network model, for example – that needed to be delivered across vast distances at lightning speed? That's when you'd call in the high-speed train: the TPU (Tensor Processing Unit). This train, built for a single purpose and confined to dedicated tracks, represents the TPU's specialization and blistering speed in handling tensor operations. While the trucks excel at flexibility, the train reigns supreme when it comes to focused, high-performance delivery. Let's explore how this analogy helps us understand the fundamental differences and trade-offs between GPUs and TPUs in the world of machine learning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3OHPLv_y0lF"
      },
      "id": "b3OHPLv_y0lF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-02-5c29de03a4b7 (May 30, 2025, 1:55:17 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}